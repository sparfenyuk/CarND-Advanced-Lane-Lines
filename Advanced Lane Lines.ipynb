{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin camera calibration with loading given images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def load_images(load_path):\n",
    "    image_paths = glob.glob(load_path)\n",
    "    images = [plt.imread(path) for path in image_paths]\n",
    "    return images\n",
    "        \n",
    "def display_grid(images, n_col, title, cmap=None):\n",
    "    plt.close('all')\n",
    "    fig, ax_arr = plt.subplots(len(images)//n_col, n_col,figsize=(15,7))\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(title, fontsize=30)\n",
    "    for i, image in enumerate(images):\n",
    "        ax = ax_arr[i // n_col, i % n_col]\n",
    "        ax.imshow(image,cmap=cmap)\n",
    "#         ax.set_xticks([]), ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "calibration_images = load_images(\"camera_cal/*.jpg\")\n",
    "display_grid(calibration_images, 5, \"Images for camera calibration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above there are 20 images. Using them we could do camera calibration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_corners(image, pattern_size):\n",
    "    \"\"\"\n",
    "    Look for the corners on chessboard image given pattern size\n",
    "    \n",
    "    Args:\n",
    "        image: cv2.image\n",
    "        pattern_size: tuple\n",
    "    \n",
    "    Returns:\n",
    "        List of corners coordinates if they are found\n",
    "    \"\"\"\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    retval, corners = cv2.findChessboardCorners(gray, pattern_size)\n",
    "    return corners if retval else []\n",
    "\n",
    "import functools\n",
    "\n",
    "def find_calibration_parameters(images, pattern_size):\n",
    "    return_corners = list(map(lambda x: find_corners(x, pattern_size), images))\n",
    "    corners = list(filter(lambda x: len(x) != 0, return_corners))\n",
    "\n",
    "    objp_size = np.prod(pattern_size), 3\n",
    "    objp = np.zeros(objp_size, np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1,2)\n",
    "    objpoints = [objp] * len(corners)\n",
    "    \n",
    "    image_size = images[-1].shape[1::-1]\n",
    "    ret, mtx, dist, *rest = cv2.calibrateCamera(objpoints, corners, image_size, None, None)\n",
    "    \n",
    "    return ret, mtx, dist, return_corners\n",
    "\n",
    "def undistort_images(images, mtx, dist):\n",
    "    return [cv2.undistort(image, mtx, dist) for image in images]\n",
    "\n",
    "def transform_perspective(image, corners, pattern_size = (2,2), offset = 0):\n",
    "    if len(corners) == 0:\n",
    "        img = image.copy()\n",
    "        cv2.putText(img, \"Failed\", (10, 100), cv2.FONT_ITALIC, 4.0, (0, 0, 255), 3)\n",
    "        return img\n",
    "    nx, ny = pattern_size\n",
    "    src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n",
    "    image_size = image.shape[1::-1]\n",
    "    (w, h), d = image_size, offset\n",
    "    dst = np.float32([[d, d], [w - d, d], [w-d, h-d], [d, h - d]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    return cv2.warpPerspective(image, M, image_size)\n",
    "\n",
    "ps = (9, 6)\n",
    "ret, mtx, dist, corners = find_calibration_parameters(calibration_images, pattern_size=ps)\n",
    "\n",
    "if ret:\n",
    "    undistorted_images = undistort_images(calibration_images, mtx, dist)\n",
    "#     display_grid(undistorted_images, 5, \"Undistorted images\")\n",
    "\n",
    "    transformed_images = [transform_perspective(image, corners[i], pattern_size=ps, offset=100) \\\n",
    "                          for i, image in enumerate(undistorted_images)]\n",
    "    display_grid(transformed_images, 5, \"Transformed images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It's interesting to note that some images aren't helpful because the `findChessboardCorners` method cannot detect corners on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline (for `test_images` folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_images = load_images(\"test_images/*.jpg\")\n",
    "display_grid(test_images, 4, \"Test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def undistort_and_transform_perspective(images):\n",
    "    undistorted_images = undistort_images(images, mtx, dist)\n",
    "    h, w, *_ = images[-1].shape\n",
    "    corners = [(0.35*w, 0.7*h), (0.65*w, 0.7*h), (0, 0.9*h), (w, 0.9*h)]\n",
    "    transformed_images = [transform_perspective(image, corners) \\\n",
    "                          for i, image in enumerate(undistorted_images)]\n",
    "    display_grid(transformed_images, 4, \"Transformed images\")\n",
    "    \n",
    "undistort_and_transform_perspective(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_sobel_op(gray, sobel_kernel = 3):\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    return sobelx, sobely\n",
    "\n",
    "def abs_sobel_thresh(sobelx, sobely, orient='x', thresh = (0, 255)):\n",
    "    \n",
    "    abs_sobel = np.absolute(sobelx) if orient == 'x' else np.absolute(sobely)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(sobelx, sobely, thresh=(0, 255)):\n",
    "    abs_sobel_xy = np.sqrt(sobelx ** 2 + sobely ** 2)\n",
    "    abs_sobel_xy = (abs_sobel_xy * 255 / np.max(abs_sobel_xy)).astype(np.uint8)\n",
    "\n",
    "    binary_output = np.zeros_like(abs_sobel_xy)\n",
    "    binary_output[(abs_sobel_xy >= thresh[0]) & (abs_sobel_xy <= thresh[1])] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def dir_threshold(sobelx, sobely, thresh=(0, np.pi/2)):\n",
    "    abs_sobelx, abs_sobely = np.absolute(sobelx), np.absolute(sobely)\n",
    "\n",
    "    a = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    binary_output = np.zeros_like(a)\n",
    "    \n",
    "    binary_output[(a >=thresh[0]) & (a <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def image_processing_pipeline(gray):\n",
    "    sobelx, sobely = take_sobel_op(gray)\n",
    "    r = [\n",
    "        abs_sobel_thresh(orient='x', sobelx=sobelx, sobely=sobely, thresh=(35, 150)),\n",
    "        abs_sobel_thresh(orient='y', sobelx=sobelx, sobely=sobely, thresh=(10, 150)),\n",
    "        mag_thresh(sobelx=sobelx, sobely=sobely, thresh=(50, 200)),\n",
    "        dir_threshold(sobelx=sobelx, sobely=sobely, thresh=(0.7, 1.1))\n",
    "    ]\n",
    "    combined = np.zeros_like(sobelx)\n",
    "    combined[((r[0] == 1) & (r[1] == 1)) | ((r[2] == 1) & (r[3] == 1))] = 1\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def _experiment(gray):\n",
    "    sobelx, sobely = take_sobel_op(gray)\n",
    "    result = []\n",
    "    for i in range(0, 8*10, 10):\n",
    "        result.append(abs_sobel_thresh(orient='y', sobelx=sobelx, sobely=sobely, thresh=(60,60+i)))\n",
    "    print(len(result))\n",
    "    return result\n",
    "        \n",
    "#gray_test_images = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in test_images]\n",
    "converted = [image_processing_pipeline(gray) for gray in gray_test_images]\n",
    "# converted = _experiment(gray_test_images[0])\n",
    "display_grid(converted, n_col=4, title=\"Thresholded images\", cmap='gray')\n",
    "# gradient_threshold_images = [gradient_threshold(img, (20, 100)) for img in gray_test_images]\n",
    "# display_grid(gradient_threshold_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
